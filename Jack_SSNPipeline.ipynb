{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will get a take a protein family of choice from UniProt, download the sequences with annotations such as domains, PDB codes and taxonomy and then cluster by similarity using mmSEQs. \n",
    "\n",
    "The sequence space will be plotted and the most representative sequences will be taken from across the sequence space \n",
    "\n",
    "Finally the selected sequences will be analysed for solubility and expressebility in e coli \n",
    "\n",
    "Eventually this will be combined with automated analysis of the proteins in the lab to train a reinforcement learning network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you will need to go to uniprot, search for the interpro or pfam ID you are interested in. We will download 2 files, a Fasta file and a TSV file\n",
    "for the fasta file just download the default option. for TSV follow below.\n",
    "Select download, format: TSV and select the annotations you are interested in. I generally add taxnomic lineage, PDB, and domain [FT], ensure you also. Then generate URL for API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sequence data using uniprot api \n",
    "import requests\n",
    "\n",
    "url = 'https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Clineage%2Cxref_pdb%2Cft_domain&format=tsv&query=%28IPR001223%29+AND+%28reviewed%3Atrue%29' #enter your URL here\n",
    "sequences = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the API we can just download the TSV and move it to the directory you are running this notebook from. Then we will use mmseqs to clean the data create an all by all comparison, you will need to install mmseqs2 first. https://github.com/soedinglab/mmseqs2/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy-cluster input.fasta clusterRes tmp --min-seq-id 0.8 \n",
      "\n",
      "MMseqs Version:                     \t15-6f452\n",
      "Substitution matrix                 \taa:blosum62.out,nucl:nucleotide.out\n",
      "Seed substitution matrix            \taa:VTML80.out,nucl:nucleotide.out\n",
      "Sensitivity                         \t4\n",
      "k-mer length                        \t0\n",
      "Target search mode                  \t0\n",
      "k-score                             \tseq:2147483647,prof:2147483647\n",
      "Alphabet size                       \taa:21,nucl:5\n",
      "Max sequence length                 \t65535\n",
      "Max results per query               \t20\n",
      "Split database                      \t0\n",
      "Split mode                          \t2\n",
      "Split memory limit                  \t0\n",
      "Coverage threshold                  \t0.8\n",
      "Coverage mode                       \t0\n",
      "Compositional bias                  \t1\n",
      "Compositional bias                  \t1\n",
      "Diagonal scoring                    \ttrue\n",
      "Exact k-mer matching                \t0\n",
      "Mask residues                       \t1\n",
      "Mask residues probability           \t0.9\n",
      "Mask lower case residues            \t0\n",
      "Minimum diagonal score              \t15\n",
      "Selected taxa                       \t\n",
      "Include identical seq. id.          \tfalse\n",
      "Spaced k-mers                       \t1\n",
      "Preload mode                        \t0\n",
      "Pseudo count a                      \tsubstitution:1.100,context:1.400\n",
      "Pseudo count b                      \tsubstitution:4.100,context:5.800\n",
      "Spaced k-mer pattern                \t\n",
      "Local temporary path                \t\n",
      "Threads                             \t10\n",
      "Compressed                          \t0\n",
      "Verbosity                           \t3\n",
      "Add backtrace                       \tfalse\n",
      "Alignment mode                      \t3\n",
      "Alignment mode                      \t0\n",
      "Allow wrapped scoring               \tfalse\n",
      "E-value threshold                   \t0.001\n",
      "Seq. id. threshold                  \t0.8\n",
      "Min alignment length                \t0\n",
      "Seq. id. mode                       \t0\n",
      "Alternative alignments              \t0\n",
      "Max reject                          \t2147483647\n",
      "Max accept                          \t2147483647\n",
      "Score bias                          \t0\n",
      "Realign hits                        \tfalse\n",
      "Realign score bias                  \t-0.2\n",
      "Realign max seqs                    \t2147483647\n",
      "Correlation score weight            \t0\n",
      "Gap open cost                       \taa:11,nucl:5\n",
      "Gap extension cost                  \taa:1,nucl:2\n",
      "Zdrop                               \t40\n",
      "Rescore mode                        \t0\n",
      "Remove hits by seq. id. and coverage\tfalse\n",
      "Sort results                        \t0\n",
      "Cluster mode                        \t0\n",
      "Max connected component depth       \t1000\n",
      "Similarity type                     \t2\n",
      "Weight file name                    \t\n",
      "Cluster Weight threshold            \t0.9\n",
      "Single step clustering              \tfalse\n",
      "Cascaded clustering steps           \t3\n",
      "Cluster reassign                    \tfalse\n",
      "Remove temporary files              \ttrue\n",
      "Force restart with latest tmp       \tfalse\n",
      "MPI runner                          \t\n",
      "k-mers per sequence                 \t21\n",
      "Scale k-mers per sequence           \taa:0.000,nucl:0.200\n",
      "Adjust k-mer length                 \tfalse\n",
      "Shift hash                          \t67\n",
      "Include only extendable             \tfalse\n",
      "Skip repeating k-mers               \tfalse\n",
      "Database type                       \t0\n",
      "Shuffle input database              \ttrue\n",
      "Createdb mode                       \t1\n",
      "Write lookup file                   \t0\n",
      "Offset of numeric ids               \t0\n",
      "\n",
      "createdb input.fasta tmp/10382936441253150374/input --dbtype 0 --shuffle 1 --createdb-mode 1 --write-lookup 0 --id-offset 0 --compressed 0 -v 3 \n",
      "\n",
      "\u001b[33mShuffle database cannot be combined with --createdb-mode 0\n",
      "\u001b[39m\u001b[33mWe recompute with --shuffle 0\n",
      "\u001b[39mConverting sequences\n",
      "\u001b[33mMultiline fasta can not be combined with --createdb-mode 0\n",
      "\u001b[39m\u001b[33mWe recompute with --createdb-mode 1\n",
      "\u001b[39mTime for merging to input_h: 0h 0m 0s 0ms\n",
      "Time for merging to input: 0h 0m 0s 0ms\n",
      "[102] 0s 2ms\n",
      "Time for merging to input_h: 0h 0m 0s 0ms\n",
      "Time for merging to input: 0h 0m 0s 0ms\n",
      "Database type: Aminoacid\n",
      "Time for processing: 0h 0m 0s 4ms\n",
      "Create directory tmp/10382936441253150374/clu_tmp\n",
      "cluster tmp/10382936441253150374/input tmp/10382936441253150374/clu tmp/10382936441253150374/clu_tmp --max-seqs 20 -c 0.8 --spaced-kmer-mode 1 --alignment-mode 3 -e 0.001 --min-seq-id 0.8 --remove-tmp-files 1 \n",
      "\n",
      "Set cluster sensitivity to -s 1.000000\n",
      "Set cluster mode SET COVER\n",
      "Set cluster iterations to 1\n",
      "linclust tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust --cluster-mode 0 --max-iterations 1000 --similarity-type 2 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 3 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0.8 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0.8 --cov-mode 0 --max-seq-len 65535 --comp-bias-corr 0 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 2147483647 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --alph-size aa:13,nucl:5 --kmer-per-seq 21 --spaced-kmer-mode 1 --kmer-per-seq-scale aa:0.000,nucl:0.200 --adjust-kmer-len 0 --mask 0 --mask-prob 0.9 --mask-lower-case 0 -k 0 --hash-shift 67 --split-memory-limit 0 --include-only-extendable 0 --ignore-multi-kmer 0 --rescore-mode 0 --filter-hits 0 --sort-results 0 --remove-tmp-files 1 --force-reuse 0 \n",
      "\n",
      "kmermatcher tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --alph-size aa:13,nucl:5 --min-seq-id 0.8 --kmer-per-seq 21 --spaced-kmer-mode 1 --kmer-per-seq-scale aa:0.000,nucl:0.200 --adjust-kmer-len 0 --mask 0 --mask-prob 0.9 --mask-lower-case 0 --cov-mode 0 -k 0 -c 0.8 --max-seq-len 65535 --hash-shift 67 --split-memory-limit 0 --include-only-extendable 0 --ignore-multi-kmer 0 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n",
      "\n",
      "kmermatcher tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --alph-size aa:13,nucl:5 --min-seq-id 0.8 --kmer-per-seq 21 --spaced-kmer-mode 1 --kmer-per-seq-scale aa:0.000,nucl:0.200 --adjust-kmer-len 0 --mask 0 --mask-prob 0.9 --mask-lower-case 0 --cov-mode 0 -k 0 -c 0.8 --max-seq-len 65535 --hash-shift 67 --split-memory-limit 0 --include-only-extendable 0 --ignore-multi-kmer 0 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n",
      "\n",
      "Database size: 174 type: Aminoacid\n",
      "Reduced amino acid alphabet: (A S T) (C) (D B N) (E Q Z) (F Y) (G) (H) (I V) (K R) (L J M) (P) (W) (X) \n",
      "\n",
      "Generate k-mers list for 1 split\n",
      "[=================================================================] 100.00% 174 0s 1ms      \n",
      "Sort kmer 0h 0m 0s 0ms\n",
      "Sort by rep. sequence 0h 0m 0s 0ms\n",
      "Time for fill: 0h 0m 0s 0ms\n",
      "Time for merging to pref: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 9ms\n",
      "rescorediagonal tmp/10382936441253150374/input tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore1 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --rescore-mode 0 --wrapped-scoring 0 --filter-hits 0 -e 0.001 -c 0.8 -a 0 --cov-mode 0 --min-seq-id 0.8 --min-aln-len 0 --seq-id-mode 0 --add-self-matches 0 --sort-results 0 --db-load-mode 0 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 174 0s 1ms      \n",
      "Time for merging to pref_rescore1: 0h 0m 0s 0ms=================> ] 98.27% 171 eta 0s       \n",
      "Time for processing: 0h 0m 0s 6ms\n",
      "clust tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore1 tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pre_clust --cluster-mode 0 --max-iterations 1000 --similarity-type 2 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n",
      "\n",
      "Clustering mode: Set Cover\n",
      "[=================================================================] 100.00% 174 0s 1ms      \n",
      "Sort entries\n",
      "Find missing connections\n",
      "Found 42 new connections.\n",
      "Reconstruct initial order\n",
      "[=================================================================] 100.00% 174 0s 1ms      \n",
      "Add missing connections\n",
      "[=================================================================] 100.00% 174 0s 0ms      \n",
      "\n",
      "Time for read in: 0h 0m 0s 4ms\n",
      "Total time: 0h 0m 0s 5ms\n",
      "\n",
      "Size of the sequence database: 174\n",
      "Size of the alignment database: 174\n",
      "Number of clusters: 142\n",
      "\n",
      "Writing results 0h 0m 0s 0ms\n",
      "Time for merging to pre_clust: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 6ms\n",
      "createsubdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/order_redundancy tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy -v 3 --subdb-mode 1 \n",
      "\n",
      "Time for merging to input_step_redundancy: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "createsubdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/order_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter1 -v 3 --subdb-mode 1 \n",
      "\n",
      "Time for merging to pref_filter1: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "filterdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter1 tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter2 --filter-file tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/order_redundancy --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Filtering using file(s)\n",
      "[=================================================================] 100.00% 142 0s 1ms      \n",
      "Time for merging to pref_filter2: 0h 0m 0s 1ms\n",
      "Time for processing: 0h 0m 0s 6ms\n",
      "rescorediagonal tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter2 tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore2 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --rescore-mode 1 --wrapped-scoring 0 --filter-hits 1 -e 0.001 -c 0.8 -a 0 --cov-mode 0 --min-seq-id 0.8 --min-aln-len 0 --seq-id-mode 0 --add-self-matches 0 --sort-results 0 --db-load-mode 0 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 142 0s 1ms      \n",
      "Time for merging to pref_rescore2: 0h 0m 0s 1ms\n",
      "Time for processing: 0h 0m 0s 7ms\n",
      "align tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore2 tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/aln --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 3 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0.8 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0.8 --cov-mode 0 --max-seq-len 65535 --comp-bias-corr 0 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 2147483647 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Compute score, coverage and sequence identity\n",
      "Query database size: 142 type: Aminoacid\n",
      "Target database size: 142 type: Aminoacid\n",
      "Calculation of alignments\n",
      "[=================================================================] 100.00% 142 0s 7ms      \n",
      "Time for merging to aln: 0h 0m 0s 0ms\n",
      "184 alignments calculated\n",
      "150 sequence pairs passed the thresholds (0.815217 of overall calculated)\n",
      "1.056338 hits per query sequence\n",
      "Time for processing: 0h 0m 0s 12ms\n",
      "clust tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/aln tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/clust --cluster-mode 0 --max-iterations 1000 --similarity-type 2 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n",
      "\n",
      "Clustering mode: Set Cover\n",
      "[=================================================================] 100.00% 142 0s 0ms      \n",
      "Sort entries\n",
      "Find missing connections\n",
      "Found 8 new connections.\n",
      "Reconstruct initial order\n",
      "[=================================================================] 100.00% 142 0s 1ms      ==========>                  ] 70.92% 101 eta 0s       \n",
      "Add missing connections\n",
      "[=================================================================] 100.00% 142 0s 0ms      \n",
      "\n",
      "Time for read in: 0h 0m 0s 4ms\n",
      "Total time: 0h 0m 0s 4ms\n",
      "\n",
      "Size of the sequence database: 142\n",
      "Size of the alignment database: 142\n",
      "Number of clusters: 134\n",
      "\n",
      "Writing results 0h 0m 0s 0ms\n",
      "Time for merging to clust: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 5ms\n",
      "mergeclusters tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pre_clust tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/clust --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Clustering step 1\n",
      "[=================================================================] 100.00% 142 0s 0ms      \n",
      "Clustering step 2\n",
      "[=================================================================] 100.00% 134 0s 1ms      \n",
      "Write merged clustering\n",
      "[=================================================================] 100.00% 174 0s 4ms      \n",
      "Time for merging to clu_redundancy: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 6ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter1 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore1 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pre_clust -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/input_step_redundancy_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_filter2 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/pref_rescore2 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/aln -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/linclust/11777057188852432909/clust -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "createsubdb tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_redundancy tmp/10382936441253150374/input tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy -v 3 --subdb-mode 1 \n",
      "\n",
      "Time for merging to input_step_redundancy: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 2ms\n",
      "prefilter tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/pref_step0 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --seed-sub-mat 'aa:VTML80.out,nucl:nucleotide.out' -s 1 -k 0 --target-search-mode 0 --k-score seq:2147483647,prof:2147483647 --alph-size aa:21,nucl:5 --max-seq-len 65535 --max-seqs 20 --split 0 --split-mode 2 --split-memory-limit 0 -c 0.8 --cov-mode 0 --comp-bias-corr 0 --comp-bias-corr-scale 1 --diag-score 0 --exact-kmer-matching 0 --mask 1 --mask-prob 0.9 --mask-lower-case 0 --min-ungapped-score 0 --add-self-matches 0 --spaced-kmer-mode 1 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Query database size: 134 type: Aminoacid\n",
      "Estimated memory consumption: 978M\n",
      "Target database size: 134 type: Aminoacid\n",
      "Index table k-mer threshold: 154 at k-mer size 6 \n",
      "Index table: counting k-mers\n",
      "[=================================================================] 100.00% 134 0s 44ms     \n",
      "Index table: Masked residues: 2672\n",
      "Index table: fill\n",
      "[=================================================================] 100.00% 134 0s 4ms      \n",
      "Index statistics\n",
      "Entries:          32526\n",
      "DB size:          488 MB\n",
      "Avg k-mer size:   0.000508\n",
      "Top 10 k-mers\n",
      "    DGDDYP\t24\n",
      "    LKLSGW\t18\n",
      "    FDVVYN\t11\n",
      "    GLDVQF\t9\n",
      "    DGDDFP\t9\n",
      "    CYTWYR\t9\n",
      "    GWFTFT\t9\n",
      "    GLLWPG\t8\n",
      "    GNQPNL\t8\n",
      "    YFNARP\t8\n",
      "Time for index table init: 0h 0m 0s 305ms\n",
      "Process prefiltering step 1 of 1\n",
      "\n",
      "k-mer similarity threshold: 154\n",
      "Starting prefiltering scores calculation (step 1 of 1)\n",
      "Query db start 1 to 134\n",
      "Target db start 1 to 134\n",
      "[=================================================================] 100.00% 134 0s 51ms     \n",
      "\n",
      "2.262791 k-mers per position\n",
      "377 DB matches per sequence\n",
      "0 overflows\n",
      "9 sequences passed prefiltering per query sequence\n",
      "10 median result list length\n",
      "0 sequences with 0 size result lists\n",
      "Time for merging to pref_step0: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 760ms\n",
      "align tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/pref_step0 tmp/10382936441253150374/clu_tmp/4438291003651752844/aln_step0 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 3 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0.8 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0.8 --cov-mode 0 --max-seq-len 65535 --comp-bias-corr 0 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 2147483647 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Compute score, coverage and sequence identity\n",
      "Query database size: 134 type: Aminoacid\n",
      "Target database size: 134 type: Aminoacid\n",
      "Calculation of alignments\n",
      "[=================================================================] 100.00% 134 0s 74ms     \n",
      "Time for merging to aln_step0: 0h 0m 0s 2ms\n",
      "850 alignments calculated\n",
      "140 sequence pairs passed the thresholds (0.164706 of overall calculated)\n",
      "1.044776 hits per query sequence\n",
      "Time for processing: 0h 0m 0s 87ms\n",
      "clust tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/aln_step0 tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_step0 --cluster-mode 0 --max-iterations 1000 --similarity-type 2 --threads 10 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n",
      "\n",
      "Clustering mode: Set Cover\n",
      "[=================================================================] 100.00% 134 0s 0ms      \n",
      "Sort entries\n",
      "Find missing connections\n",
      "Found 0 new connections.\n",
      "Reconstruct initial order\n",
      "[=================================================================] 100.00% 134 0s 0ms      \n",
      "Add missing connections\n",
      "[=================================================================] 100.00% 134 0s 0ms      \n",
      "\n",
      "Time for read in: 0h 0m 0s 3ms\n",
      "Total time: 0h 0m 0s 3ms\n",
      "\n",
      "Size of the sequence database: 134\n",
      "Size of the alignment database: 134\n",
      "Number of clusters: 131\n",
      "\n",
      "Writing results 0h 0m 0s 0ms\n",
      "Time for merging to clu_step0: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 5ms\n",
      "mergeclusters tmp/10382936441253150374/input tmp/10382936441253150374/clu tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_redundancy tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_step0 --threads 10 --compressed 0 -v 3 \n",
      "\n",
      "Clustering step 1\n",
      "[=================================================================] 100.00% 134 0s 0ms      \n",
      "Clustering step 2\n",
      "[=================================================================] 100.00% 131 0s 1ms      \n",
      "Write merged clustering\n",
      "[=================================================================] 100.00% 174 0s 4ms      \n",
      "Time for merging to clu: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 6ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_redundancy -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/input_step_redundancy_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/pref_step0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/aln_step0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_tmp/4438291003651752844/clu_step0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "createtsv tmp/10382936441253150374/input tmp/10382936441253150374/input tmp/10382936441253150374/clu tmp/10382936441253150374/cluster.tsv --threads 10 -v 3 \n",
      "\n",
      "Time for merging to cluster.tsv: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 3ms\n",
      "result2repseq tmp/10382936441253150374/input tmp/10382936441253150374/clu tmp/10382936441253150374/clu_rep --db-load-mode 0 --compressed 0 --threads 10 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 131 0s 0ms      \n",
      "Time for merging to clu_rep: 0h 0m 0s 1ms\n",
      "Time for processing: 0h 0m 0s 5ms\n",
      "result2flat tmp/10382936441253150374/input tmp/10382936441253150374/input tmp/10382936441253150374/clu_rep tmp/10382936441253150374/rep_seq.fasta --use-fasta-header -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "createseqfiledb tmp/10382936441253150374/input tmp/10382936441253150374/clu tmp/10382936441253150374/clu_seqs --threads 10 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 131 0s 1ms      \n",
      "Time for merging to clu_seqs: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 4ms\n",
      "result2flat tmp/10382936441253150374/input tmp/10382936441253150374/input tmp/10382936441253150374/clu_seqs tmp/10382936441253150374/all_seqs.fasta -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "rmdb tmp/10382936441253150374/input -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/input_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_seqs -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu_rep -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/10382936441253150374/clu -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n"
     ]
    }
   ],
   "source": [
    "# remove sequences with greater than 0.8 sequence identity\n",
    "!mmseqs easy-cluster input.fasta clusterRes tmp --min-seq-id 0.8 #clusters sequences with 80% similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the dataset we need to do an all by all comparison to cluster the sequences by similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mall_by_all.tsv exists and will be overwritten\n",
      "\u001b[39measy-search clusterRes_rep_seq.fasta clusterRes_rep_seq.fasta all_by_all.tsv /tmp --threads 8 \n",
      "\n",
      "MMseqs Version:                        \t15-6f452\n",
      "Substitution matrix                    \taa:blosum62.out,nucl:nucleotide.out\n",
      "Add backtrace                          \tfalse\n",
      "Alignment mode                         \t3\n",
      "Alignment mode                         \t0\n",
      "Allow wrapped scoring                  \tfalse\n",
      "E-value threshold                      \t0.001\n",
      "Seq. id. threshold                     \t0\n",
      "Min alignment length                   \t0\n",
      "Seq. id. mode                          \t0\n",
      "Alternative alignments                 \t0\n",
      "Coverage threshold                     \t0\n",
      "Coverage mode                          \t0\n",
      "Max sequence length                    \t65535\n",
      "Compositional bias                     \t1\n",
      "Compositional bias                     \t1\n",
      "Max reject                             \t2147483647\n",
      "Max accept                             \t2147483647\n",
      "Include identical seq. id.             \tfalse\n",
      "Preload mode                           \t0\n",
      "Pseudo count a                         \tsubstitution:1.100,context:1.400\n",
      "Pseudo count b                         \tsubstitution:4.100,context:5.800\n",
      "Score bias                             \t0\n",
      "Realign hits                           \tfalse\n",
      "Realign score bias                     \t-0.2\n",
      "Realign max seqs                       \t2147483647\n",
      "Correlation score weight               \t0\n",
      "Gap open cost                          \taa:11,nucl:5\n",
      "Gap extension cost                     \taa:1,nucl:2\n",
      "Zdrop                                  \t40\n",
      "Threads                                \t8\n",
      "Compressed                             \t0\n",
      "Verbosity                              \t3\n",
      "Seed substitution matrix               \taa:VTML80.out,nucl:nucleotide.out\n",
      "Sensitivity                            \t5.7\n",
      "k-mer length                           \t0\n",
      "Target search mode                     \t0\n",
      "k-score                                \tseq:2147483647,prof:2147483647\n",
      "Alphabet size                          \taa:21,nucl:5\n",
      "Max results per query                  \t300\n",
      "Split database                         \t0\n",
      "Split mode                             \t2\n",
      "Split memory limit                     \t0\n",
      "Diagonal scoring                       \ttrue\n",
      "Exact k-mer matching                   \t0\n",
      "Mask residues                          \t1\n",
      "Mask residues probability              \t0.9\n",
      "Mask lower case residues               \t0\n",
      "Minimum diagonal score                 \t15\n",
      "Selected taxa                          \t\n",
      "Spaced k-mers                          \t1\n",
      "Spaced k-mer pattern                   \t\n",
      "Local temporary path                   \t\n",
      "Rescore mode                           \t0\n",
      "Remove hits by seq. id. and coverage   \tfalse\n",
      "Sort results                           \t0\n",
      "Mask profile                           \t1\n",
      "Profile E-value threshold              \t0.001\n",
      "Global sequence weighting              \tfalse\n",
      "Allow deletions                        \tfalse\n",
      "Filter MSA                             \t1\n",
      "Use filter only at N seqs              \t0\n",
      "Maximum seq. id. threshold             \t0.9\n",
      "Minimum seq. id.                       \t0.0\n",
      "Minimum score per column               \t-20\n",
      "Minimum coverage                       \t0\n",
      "Select N most diverse seqs             \t1000\n",
      "Pseudo count mode                      \t0\n",
      "Min codons in orf                      \t30\n",
      "Max codons in length                   \t32734\n",
      "Max orf gaps                           \t2147483647\n",
      "Contig start mode                      \t2\n",
      "Contig end mode                        \t2\n",
      "Orf start mode                         \t1\n",
      "Forward frames                         \t1,2,3\n",
      "Reverse frames                         \t1,2,3\n",
      "Translation table                      \t1\n",
      "Translate orf                          \t0\n",
      "Use all table starts                   \tfalse\n",
      "Offset of numeric ids                  \t0\n",
      "Create lookup                          \t0\n",
      "Add orf stop                           \tfalse\n",
      "Overlap between sequences              \t0\n",
      "Sequence split mode                    \t1\n",
      "Header split mode                      \t0\n",
      "Chain overlapping alignments           \t0\n",
      "Merge query                            \t1\n",
      "Search type                            \t0\n",
      "Search iterations                      \t1\n",
      "Start sensitivity                      \t4\n",
      "Search steps                           \t1\n",
      "Prefilter mode                         \t0\n",
      "Exhaustive search mode                 \tfalse\n",
      "Filter results during exhaustive search\t0\n",
      "Strand selection                       \t1\n",
      "LCA search mode                        \tfalse\n",
      "Disk space limit                       \t0\n",
      "MPI runner                             \t\n",
      "Force restart with latest tmp          \tfalse\n",
      "Remove temporary files                 \ttrue\n",
      "Alignment format                       \t0\n",
      "Format alignment output                \tquery,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits\n",
      "Database output                        \tfalse\n",
      "Overlap threshold                      \t0\n",
      "Database type                          \t0\n",
      "Shuffle input database                 \ttrue\n",
      "Createdb mode                          \t0\n",
      "Write lookup file                      \t0\n",
      "Greedy best hits                       \tfalse\n",
      "\n",
      "createdb clusterRes_rep_seq.fasta /tmp/607007007485427206/query --dbtype 0 --shuffle 1 --createdb-mode 0 --write-lookup 0 --id-offset 0 --compressed 0 -v 3 \n",
      "\n",
      "Converting sequences\n",
      "[102] 0s 7ms\n",
      "Time for merging to query_h: 0h 0m 0s 4ms\n",
      "Time for merging to query: 0h 0m 0s 3ms\n",
      "Database type: Aminoacid\n",
      "Time for processing: 0h 0m 0s 22ms\n",
      "createdb clusterRes_rep_seq.fasta /tmp/607007007485427206/target --dbtype 0 --shuffle 1 --createdb-mode 0 --write-lookup 0 --id-offset 0 --compressed 0 -v 3 \n",
      "\n",
      "Converting sequences\n",
      "[102] 0s 7ms\n",
      "Time for merging to target_h: 0h 0m 0s 4ms\n",
      "Time for merging to target: 0h 0m 0s 3ms\n",
      "Database type: Aminoacid\n",
      "Time for processing: 0h 0m 0s 23ms\n",
      "Create directory /tmp/607007007485427206/search_tmp\n",
      "search /tmp/607007007485427206/query /tmp/607007007485427206/target /tmp/607007007485427206/result /tmp/607007007485427206/search_tmp --alignment-mode 3 --threads 8 -s 5.7 --remove-tmp-files 1 \n",
      "\n",
      "prefilter /tmp/607007007485427206/query /tmp/607007007485427206/target /tmp/607007007485427206/search_tmp/5214899506324931397/pref_0 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --seed-sub-mat 'aa:VTML80.out,nucl:nucleotide.out' -k 0 --target-search-mode 0 --k-score seq:2147483647,prof:2147483647 --alph-size aa:21,nucl:5 --max-seq-len 65535 --max-seqs 300 --split 0 --split-mode 2 --split-memory-limit 0 -c 0 --cov-mode 0 --comp-bias-corr 1 --comp-bias-corr-scale 1 --diag-score 1 --exact-kmer-matching 0 --mask 1 --mask-prob 0.9 --mask-lower-case 0 --min-ungapped-score 15 --add-self-matches 0 --spaced-kmer-mode 1 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --threads 8 --compressed 0 -v 3 -s 5.7 \n",
      "\n",
      "Query database size: 131 type: Aminoacid\n",
      "Estimated memory consumption: 978M\n",
      "Target database size: 131 type: Aminoacid\n",
      "Index table k-mer threshold: 112 at k-mer size 6 \n",
      "Index table: counting k-mers\n",
      "[=================================================================] 100.00% 131 0s 19ms     \n",
      "Index table: Masked residues: 2450\n",
      "Index table: fill\n",
      "[=================================================================] 100.00% 131 0s 5ms      \n",
      "Index statistics\n",
      "Entries:          60581\n",
      "DB size:          488 MB\n",
      "Avg k-mer size:   0.000947\n",
      "Top 10 k-mers\n",
      "    DGDDYP\t24\n",
      "    LKLSGW\t18\n",
      "    FDVVYN\t11\n",
      "    VLGDIE\t10\n",
      "    GDVDDF\t10\n",
      "    GLDVQF\t9\n",
      "    LLIGFG\t9\n",
      "    VNALFG\t9\n",
      "    GIVLGG\t9\n",
      "    DGDDFP\t9\n",
      "Time for index table init: 0h 0m 0s 219ms\n",
      "Process prefiltering step 1 of 1\n",
      "\n",
      "k-mer similarity threshold: 112\n",
      "Starting prefiltering scores calculation (step 1 of 1)\n",
      "Query db start 1 to 131\n",
      "Target db start 1 to 131\n",
      "[=================================================================] 100.00% 131 0s 76ms     \n",
      "\n",
      "382.702529 k-mers per position\n",
      "1547 DB matches per sequence\n",
      "0 overflows\n",
      "46 sequences passed prefiltering per query sequence\n",
      "45 median result list length\n",
      "0 sequences with 0 size result lists\n",
      "Time for merging to pref_0: 0h 0m 0s 0ms\n",
      "Time for processing: 0h 0m 0s 637ms\n",
      "align /tmp/607007007485427206/query /tmp/607007007485427206/target /tmp/607007007485427206/search_tmp/5214899506324931397/pref_0 /tmp/607007007485427206/result --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 3 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0 --cov-mode 0 --max-seq-len 65535 --comp-bias-corr 1 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 2147483647 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --threads 8 --compressed 0 -v 3 \n",
      "\n",
      "Compute score, coverage and sequence identity\n",
      "Query database size: 131 type: Aminoacid\n",
      "Target database size: 131 type: Aminoacid\n",
      "Calculation of alignments\n",
      "[=================================================================] 100.00% 131 0s 504ms    \n",
      "Time for merging to result: 0h 0m 0s 0ms\n",
      "6057 alignments calculated\n",
      "5373 sequence pairs passed the thresholds (0.887073 of overall calculated)\n",
      "41.015266 hits per query sequence\n",
      "Time for processing: 0h 0m 0s 535ms\n",
      "rmdb /tmp/607007007485427206/search_tmp/5214899506324931397/pref_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/search_tmp/5214899506324931397/aln_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/search_tmp/5214899506324931397/input_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/search_tmp/5214899506324931397/aln_merge -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "\u001b[33mall_by_all.tsv exists and will be overwritten\n",
      "\u001b[39mconvertalis /tmp/607007007485427206/query /tmp/607007007485427206/target /tmp/607007007485427206/result all_by_all.tsv --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --format-mode 0 --format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits --translation-table 1 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --db-output 0 --db-load-mode 0 --search-type 0 --threads 8 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 131 0s 3ms      \n",
      "Time for merging to all_by_all.tsv: 0h 0m 0s 1ms\n",
      "Time for processing: 0h 0m 0s 9ms\n",
      "rmdb /tmp/607007007485427206/result -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/target -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/target_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/query -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb /tmp/607007007485427206/query_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n"
     ]
    }
   ],
   "source": [
    "# perform all by all search on cleaned sequences\n",
    "!mmseqs easy-search clusterRes_rep_seq.fasta clusterRes_rep_seq.fasta all_by_all.tsv /tmp --threads 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use John's Cluster tools package to analyse the results of the all by all search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first import the modules we need\n",
    "\n",
    "from ClusterTools.cluster_stream import cluster_stream\n",
    "from ClusterTools.cluster_progression import cluster_progression\n",
    "#from ClusterTools.circle_plot import PlotCirclesBox2D\n",
    "from ClusterTools.cluster_size_table import MakeTable\n",
    "from ClusterTools.cluster_consensus import ParseClusters\n",
    "import sys\n",
    "sys.path.append(\"./ClusterTools/\")  # replace with the actual path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below analyses how the cluster sizes vary by bitscore cutoff, other scoring metrics can be used by changing the score setting to a different column in the all_by_all.tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---cutoff: 100\n",
      "2 clusters with 126 sequences\n",
      "5 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 200\n",
      "4 clusters with 122 sequences\n",
      "9 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 300\n",
      "3 clusters with 116 sequences\n",
      "15 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 400\n",
      "4 clusters with 82 sequences\n",
      "49 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 500\n",
      "9 clusters with 35 sequences\n",
      "96 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 600\n",
      "5 clusters with 19 sequences\n",
      "112 single nodes added\n",
      "0 unconnected nodes added\n",
      "---cutoff: 700\n",
      "5 clusters with 16 sequences\n",
      "115 single nodes added\n",
      "0 unconnected nodes added\n",
      "5373 \n",
      "0.02s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_stream('all_by_all.tsv',cutoffs=[100,200,300,400,500,600,700], score = 3, directory='cluster_stream_res')\n",
    "cluster_progression('cluster_stream_res', filter = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next function creates a table with the cluster IDs and the numbers of members. list files containing uniprot IDs of interest can be added as additional arguments to locate which cluster these proteins are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster  rep_count\n",
      "0         0         66\n",
      "1         1         11\n",
      "2         2          3\n",
      "3         3          2\n",
      "40       40          1\n",
      "30       30          1\n",
      "31       31          1\n",
      "32       32          1\n",
      "33       33          1\n",
      "34       34          1\n",
      "35       35          1\n",
      "36       36          1\n",
      "37       37          1\n",
      "38       38          1\n",
      "39       39          1\n",
      "41       41          1\n",
      "28       28          1\n",
      "42       42          1\n",
      "43       43          1\n",
      "44       44          1\n",
      "45       45          1\n",
      "46       46          1\n",
      "47       47          1\n",
      "48       48          1\n",
      "49       49          1\n",
      "50       50          1\n",
      "51       51          1\n",
      "29       29          1\n",
      "26       26          1\n",
      "27       27          1\n",
      "25       25          1\n",
      "4         4          1\n",
      "5         5          1\n",
      "6         6          1\n",
      "7         7          1\n",
      "8         8          1\n",
      "9         9          1\n",
      "10       10          1\n",
      "11       11          1\n",
      "12       12          1\n",
      "13       13          1\n",
      "14       14          1\n",
      "15       15          1\n",
      "16       16          1\n",
      "17       17          1\n",
      "18       18          1\n",
      "19       19          1\n",
      "20       20          1\n",
      "21       21          1\n",
      "22       22          1\n",
      "23       23          1\n",
      "24       24          1\n",
      "52       52          1\n"
     ]
    }
   ],
   "source": [
    "clusters = MakeTable('cluster_stream_res/cluster_400.csv', )\n",
    "print(clusters)\n",
    "clusters.to_csv('cluster_size_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function, ParseClusters will create a zip file containing an Hmm and an alginment file for each cluster with the most representative sequence at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "def clusters_to_string_list(clusters):\n",
    "    # Filter clusters with at least 2 members\n",
    "    filtered_clusters = clusters[clusters['rep_count'] >= 2]  # Assuming 'rep_count' contains the member count\n",
    "    return filtered_clusters['cluster'].astype(str).tolist()\n",
    "\n",
    "cluster_list = clusters_to_string_list(clusters)\n",
    "print(cluster_list)\n",
    "\n",
    "#This function will parse the clusters and write the most representative sequences to a file\n",
    "ParseClusters(cluster_file='cluster_stream_res/cluster_400.csv', fasta_file= 'input_clean.fasta',target_clusters=cluster_list,zip_path='consensus_cutoff400.zip', id_index= 1)\n",
    "print(f'Clusters collected: {clusters}') #debugging\n",
    "\n",
    "# unzip the consensus to seperate folder\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile('consensus_cutoff500.zip', 'r') as zip_ref:\n",
    "    #zip_ref.extractall('consensus_cutoff500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes clusters of varying bit score trhesholds from JOhn's SSN workflow and compiles representatives into an 'allcluster.fasta' master file. This can be used as the basis of a phylogeny or for experimental anlaysis of the sequnence space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters collected:     cluster  rep_count\n",
      "0         0        110\n",
      "2         2          3\n",
      "1         1          3\n",
      "10       10          1\n",
      "16       16          1\n",
      "15       15          1\n",
      "14       14          1\n",
      "13       13          1\n",
      "12       12          1\n",
      "11       11          1\n",
      "9         9          1\n",
      "8         8          1\n",
      "7         7          1\n",
      "6         6          1\n",
      "5         5          1\n",
      "4         4          1\n",
      "3         3          1\n",
      "17       17          1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "directory_path = 'cluster_stream_res/'\n",
    "#create hmms and representative alignments for each cluster at each cutoff\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    clusters = MakeTable(file_path, ) \n",
    "    cluster_list = clusters_to_string_list(clusters)\n",
    "    ParseClusters(cluster_file=file_path, fasta_file= 'input_clean.fasta',target_clusters=cluster_list,zip_path=f'{filename}_consensus.zip', id_index= 1)\n",
    "    print(f'Clusters collected: {clusters}') #debugging\n",
    "\n",
    "\n",
    "#extract the fasta file containing the top hits at each cutoff and combine in allcluster.fasta output file \n",
    "# Paths\n",
    "output_directory = './extracted_fasta_files'\n",
    "combined_fasta_path = 'allcluster.fasta'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Step 1: Extract and rename each fasta file\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.zip'):\n",
    "        # Extract the number from the zip filename, e.g., '100' from 'cluster_100.csv_consensus.zip'\n",
    "        cluster_number = filename.split('_')[1].split('.')[0]\n",
    "        print(cluster_number)\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            for zip_info in zip_ref.infolist():\n",
    "                if zip_info.filename == 'cluster_top_hits.fasta':\n",
    "                    # Save each extracted fasta file with the cluster number in its filename\n",
    "                    extracted_fasta_path = os.path.join(output_directory, f'cluster_{cluster_number}_top_hits.fasta')\n",
    "                    with zip_ref.open(zip_info) as fasta_file, open(extracted_fasta_path, 'wb') as out_fasta:\n",
    "                        out_fasta.write(fasta_file.read())\n",
    "                    print(f\"Extracted {extracted_fasta_path}\")\n",
    "\n",
    "\n",
    "with open(combined_fasta_path, 'w') as combined_fasta:\n",
    "    # Loop through each .fasta file in the output directory\n",
    "    for fasta_file in Path(output_directory).glob('*.fasta'):\n",
    "        with open(fasta_file, 'r') as f:\n",
    "            combined_fasta.write(f.read())  # Write each file's content to `allcluster.fasta`\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster  rep_count\n",
      "0        0         66\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
